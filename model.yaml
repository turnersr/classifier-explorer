---
experimenter: Rafael
name: Test
model_directory: ./model_files/
metric_directory: ./classification_metrics/
X: ./datasets/X.npy
y: ./datasets/y.npy


RandomForestClassifier:
  n_estimators: [5,10, 30] #1000,1300,1500]
  n_jobs: [-1]
  max_features: [20,'sqrt', 'log2', !!null ]
  max_depth: [300,500,600, !!null ]
  
# DecisionTreeClassifier:
#   max_features: [20, 50, 100, 'sqrt', 'log2', !!null ]
#   criterion: ['gini', 'entropy']
#   splitter: ['best', 'random']
#   min_samples_split: [2,5,10,30,50]
#   max_leaf_nodes: [7,90,100, !!null ]

# ExtraTreesClassifier:
#   n_estimators: [2,3,5,20,30, 10] #1000,1300,1500]
#   n_jobs: [-1]
#   max_features: [.5,.8,.8,10,20,'sqrt', 'log2', !!null ]
#   max_depth: [50, 100,200,300,500, 600, !!null ]
  
# PassiveAggressiveClassifier:
#   C: [.1,.5,1,10,20]
#   #shuffle: [!!python/bool 'True']
#   loss: ['squared_hinge', 'hinge']
#   n_iter: [10]

LogisticRegression:
  C: [.1,.5,1,10,20]
  penalty: ['l1','l2']
  tol: [0.0001]

# BaggingClassifier:
#   n_estimators: [10,20,30,100]
#   max_samples: [.5,.2,10,20,50,100]
#   max_features: [10,.5,.2, 50, .8, .7, !!null ]
#   n_jobs: [-1]

# KNeighborsClassifier:
#  n_neighbors: [2,3,5,10,20]
#  p: [1,2,3,5]
  
# GradientBoostingClassifier:
#   n_estimators: [100,200,300,500,600,700,1000,1900]
#   learning_rate: [0.1, .25, 0.05, 0.01]
#   max_depth: [3,4,5,6,10,20,30, !!null ]
#   max_features: [10,20,'sqrt', 'log2', !!null ]

Transform:
  name: 'identity'
...
